import re
import os
import json
import asyncio
from loguru import logger
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime
from playwright.async_api import async_playwright

from .base import BaseProvider
from ..models import ScrapedDataItem
from ..storage import storage_manager
from ..utils.dy_downloader import DouyinVideoDownloader
from ..config import settings


class DouyinVideoProvider(BaseProvider):
    """
    æŠ–éŸ³è§†é¢‘Provider

    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. æ”¯æŒä¸å®Œæ•´é“¾æ¥ï¼ˆåªæœ‰è§†é¢‘IDï¼‰è‡ªåŠ¨è·å–ç”¨æˆ·ID
    2. ä½¿ç”¨Playwrightæµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ€æœ¯
    3. è‡ªåŠ¨ä¸‹è½½è§†é¢‘åˆ°æŒ‡å®šç›®å½•
    4. æå–å®Œæ•´çš„è§†é¢‘ä¿¡æ¯
    5. è‡ªåŠ¨ä»æµè§ˆå™¨æ•°æ®åŠ è½½Cookieå’ŒUser-Agent
    """

    def __init__(
        self,
        url: str,
        rules: dict | None = None,
        save_images: bool = False,
        output_format: str = "markdown",
        force_save: bool = True,
        cookies: Optional[str] = None,
        auto_download_video: bool = False,
    ):
        """
        åˆå§‹åŒ–æŠ–éŸ³è§†é¢‘Provider

        Args:
            url: æŠ–éŸ³è§†é¢‘URLï¼ˆæ”¯æŒä¸å®Œæ•´é“¾æ¥ï¼‰
            rules: è§„åˆ™é…ç½®ï¼ˆä¿æŒæ¥å£ä¸€è‡´ï¼‰
            save_images: æ˜¯å¦ä¿å­˜å›¾ç‰‡
            output_format: è¾“å‡ºæ ¼å¼
            force_save: æ˜¯å¦å¼ºåˆ¶ä¿å­˜
            cookies: Cookieå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»æµè§ˆå™¨æ•°æ®åŠ è½½ï¼‰
            auto_download_video: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½è§†é¢‘
        """
        if rules is None:
            rules = {}
        super().__init__(url, rules, save_images, output_format, force_save, "douyin")

        self.url = url
        self.auto_download_video = auto_download_video

        # åŠ è½½Cookieå’ŒUser-Agent
        self.cookies = cookies or self._load_saved_cookies()
        self.user_agent = self._load_user_agent()

        # åˆå§‹åŒ–ä¸‹è½½å™¨ï¼ˆä½¿ç”¨åŠ è½½çš„Cookieå’ŒUAï¼‰
        self.downloader = DouyinVideoDownloader(
            cookie=self.cookies or "", user_agent=self.user_agent
        )

    def _load_saved_cookies(self) -> Optional[str]:
        """
        åŠ è½½å·²ä¿å­˜çš„æŠ–éŸ³ç™»å½•cookies

        Returns:
            str: Cookieå­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            cookies_file = os.path.join(settings.LOGIN_DATA_DIR, "douyin_cookies.json")

            if os.path.exists(cookies_file):
                with open(cookies_file, "r", encoding="utf-8") as f:
                    cookies_list = json.load(f)
                    # è½¬æ¢ä¸ºcookieå­—ç¬¦ä¸²
                    cookie_str = "; ".join(
                        [f"{c['name']}={c['value']}" for c in cookies_list]
                    )
                    logger.info(
                        f"ğŸ“‚ åŠ è½½å·²ä¿å­˜çš„æŠ–éŸ³ç™»å½•çŠ¶æ€ï¼Œå…± {len(cookies_list)} ä¸ªcookies"
                    )
                    return cookie_str
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä¿å­˜çš„æŠ–éŸ³Cookie: {cookies_file}")
                logger.info(f"ğŸ’¡ æç¤º: å¯ä»¥è¿è¡Œæµè§ˆå™¨ç™»å½•è„šæœ¬ä¿å­˜Cookie")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½æŠ–éŸ³ç™»å½•çŠ¶æ€å¤±è´¥: {e}")

        return None

    def _load_user_agent(self) -> str:
        """
        åŠ è½½User-Agent,ä¼˜å…ˆçº§:
        1. user_agent.txt æ–‡ä»¶
        2. settings.USER_AGENT é…ç½®

        Returns:
            str: User-Agentå­—ç¬¦ä¸²
        """

        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„User-Agent
        logger.debug(f"ğŸ“ ä½¿ç”¨é…ç½®çš„User-Agent")
        return settings.USER_AGENT

    async def _get_user_id_from_browser(self, video_url: str) -> Optional[str]:
        """
        ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–ç”¨æˆ·ID

        Args:
            video_url: è§†é¢‘URL

        Returns:
            str: ç”¨æˆ·IDï¼Œå¤±è´¥è¿”å›None
        """
        logger.debug(f"   ğŸŒ ä½¿ç”¨æµè§ˆå™¨è·å–ç”¨æˆ·ID...")

        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                )
                page = await context.new_page()

                try:
                    logger.debug("   â³ æ­£åœ¨åŠ è½½é¡µé¢...")
                    await page.goto(video_url, wait_until="networkidle", timeout=30000)
                    await asyncio.sleep(3)

                    html_content = await page.content()
                    pattern = r"https://www\.douyin\.com/user/([A-Za-z0-9_-]+)"
                    matches = re.findall(pattern, html_content)

                    if matches:
                        user_id = matches[0]
                        logger.debug(f"   âœ… æˆåŠŸè·å–ç”¨æˆ·ID: {user_id[:30]}...")
                        return user_id
                    else:
                        logger.error("   âŒ æœªåœ¨ç½‘é¡µä¸­æ‰¾åˆ°ç”¨æˆ·ID")
                        return None
                except Exception as e:
                    logger.error(f"   âŒ è·å–å¤±è´¥: {e}")
                    return None
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"   âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    async def _build_complete_url(self, url: str) -> Optional[str]:
        """
        å°†ä¸å®Œæ•´é“¾æ¥è½¬æ¢ä¸ºå®Œæ•´é“¾æ¥

        Args:
            url: åŸå§‹URLï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰

        Returns:
            str: å®Œæ•´çš„URLï¼Œå¤±è´¥è¿”å›None
        """
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´é“¾æ¥ï¼Œç›´æ¥è¿”å›
        if "/user/" in url:
            logger.debug("   âœ… å·²ç»æ˜¯å®Œæ•´é“¾æ¥")
            return url

        # æå–è§†é¢‘ID
        video_id_match = re.search(r"/video/(\d+)", url)
        if not video_id_match:
            logger.error("   âŒ æ— æ³•ä»é“¾æ¥ä¸­æå–è§†é¢‘ID")
            return None

        video_id = video_id_match.group(1)
        logger.debug(f"   ğŸ“¹ è§†é¢‘ID: {video_id}")

        # ä½¿ç”¨æµè§ˆå™¨è·å–ç”¨æˆ·ID
        user_id = await self._get_user_id_from_browser(url)
        if not user_id:
            return None

        # æ‹¼æ¥å®Œæ•´é“¾æ¥
        complete_url = f"https://www.douyin.com/user/{user_id}/video/{video_id}"
        logger.debug(f"   âœ… å®Œæ•´é“¾æ¥: {complete_url[:80]}...")
        return complete_url

    async def fetch_and_parse(self) -> ScrapedDataItem:
        """
        è·å–å¹¶è§£ææŠ–éŸ³è§†é¢‘ä¿¡æ¯

        Returns:
            ScrapedDataItem: åŒ…å«è§†é¢‘ä¿¡æ¯çš„æ•°æ®é¡¹
        """
        try:
            logger.debug(
                "\n" + "=" * 80 + "\nğŸ¬ æŠ–éŸ³è§†é¢‘Provider - å¼€å§‹å¤„ç†\n" + "=" * 80
            )
            logger.debug(f"\nğŸ“ è¾“å…¥é“¾æ¥: {self.url}")

            # 1. å¤„ç†é“¾æ¥ï¼ˆå¦‚æœéœ€è¦è¡¥å…¨ï¼‰
            logger.debug("\nğŸ”§ æ­£åœ¨å¤„ç†é“¾æ¥...")
            complete_url = await self._build_complete_url(self.url)

            if not complete_url:
                raise Exception("æ— æ³•è·å–å®Œæ•´é“¾æ¥")

            # 2. è§£æURLè·å–è§†é¢‘IDå’Œç”¨æˆ·ID
            logger.debug("\nğŸ” æ­£åœ¨è§£ææŠ–éŸ³é“¾æ¥...")
            parse_result = await self.downloader.parse_share_url(complete_url)

            if not parse_result or "aweme_id" not in parse_result:
                raise Exception("æ— æ³•è§£æè§†é¢‘é“¾æ¥")

            aweme_id = parse_result["aweme_id"]
            sec_user_id = parse_result.get("sec_user_id")

            logger.info(f"   âœ… è§£ææˆåŠŸ!")
            logger.info(f"   ä½œå“ID: {aweme_id}")
            if sec_user_id:
                logger.info(f"   ç”¨æˆ·ID: {sec_user_id[:20]}...")

            # 3. ä»ç”¨æˆ·ä½œå“åˆ—è¡¨ä¸­æŸ¥æ‰¾è§†é¢‘ï¼ˆæ›´å¯é çš„æ–¹æ³•ï¼‰
            aweme = None
            if sec_user_id:
                logger.info("\nï¿½ ä»ç”¨æˆ·ä½œå“åˆ—è¡¨ä¸­æŸ¥æ‰¾è§†é¢‘...")
                aweme = await self.downloader.find_video_in_posts(sec_user_id, aweme_id)

            # å¦‚æœfind_video_in_postså¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥è·å–è¯¦æƒ…
            if not aweme:
                logger.info("\nğŸ“¥ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘è¯¦æƒ…...")
                aweme = await self.downloader.fetch_aweme_detail(aweme_id)

            if not aweme:
                raise Exception("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")

            # 4. æå–è§†é¢‘ä¿¡æ¯
            video_info = self.downloader.extract_video_info(aweme)
            video_info["complete_url"] = complete_url

            # æ‰“å°è§†é¢‘ä¿¡æ¯
            self.downloader.print_video_info(video_info)

            # 5. åˆ›å»ºå­˜å‚¨ç›®å½•ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
            storage_info = None
            if self.force_save:
                storage_info = storage_manager.create_article_storage(
                    platform=self.platform_name,
                    title=video_info.get("desc", "æŠ–éŸ³è§†é¢‘"),
                    url=self.url,
                )

            # 6. è‡ªåŠ¨ä¸‹è½½è§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.auto_download_video and storage_info:
                logger.info(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘...")

                # è·å–è§†é¢‘ä¸‹è½½åœ°å€
                video_url = video_info["video"].get("download_url") or video_info[
                    "video"
                ].get("play_url")

                if not video_url:
                    logger.warning("   âš ï¸ æœªæ‰¾åˆ°è§†é¢‘ä¸‹è½½åœ°å€")
                else:
                    # æ„é€ æ–‡ä»¶å
                    author_name = video_info["author"]["nickname"]
                    desc = video_info["desc"][:30]

                    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                    safe_author = re.sub(r'[<>:"/\\|?*]', "_", author_name)
                    safe_desc = re.sub(r'[<>:"/\\|?*]', "_", desc)

                    filename = f"{safe_author}_{aweme_id}_{safe_desc}.mp4"
                    save_path = os.path.join(storage_info["article_dir"], filename)

                    # ä¸‹è½½è§†é¢‘
                    success = await self.downloader.download_video(video_url, save_path)

                    if success:
                        video_info["local_video_path"] = save_path
                        # è·å–æ–‡ä»¶å¤§å°
                        file_size = Path(save_path).stat().st_size / (1024 * 1024)
                        logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                    else:
                        logger.error(f"   âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥")

            # 7. åˆ›å»ºScrapedDataItem
            title = video_info.get("desc", "æŠ–éŸ³è§†é¢‘")
            author_name = video_info.get("author", {}).get("nickname", "æœªçŸ¥ä½œè€…")

            # æ ¼å¼åŒ–å†…å®¹æ–‡æœ¬
            content_text = self._format_video_info_text(video_info)
            markdown_content = self._format_as_markdown_from_downloader_info(video_info)

            # 8. ä¿å­˜åˆ°æœ¬åœ°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.force_save and storage_info:
                # ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´æ•°æ®
                json_path = os.path.join(storage_info["article_dir"], "video_info.json")
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(video_info, f, ensure_ascii=False, indent=2)

                # ä¿å­˜æ–‡æœ¬å†…å®¹
                storage_manager.save_text_content(storage_info, content_text)

                # ä¿å­˜markdownæ ¼å¼
                storage_manager.save_markdown_content(
                    storage_info, markdown_content, title
                )

                # ä¿å­˜æ–‡ç« ç´¢å¼•
                storage_manager.save_article_index(
                    storage_info, video_info.get("desc", "")[:200]
                )

            item = ScrapedDataItem(
                title=title,
                author=author_name,
                content=content_text,
                markdown_content=markdown_content,
                images=[],
                save_directory=(
                    storage_info.get("article_dir") if storage_info else None
                ),
            )

            logger.info("\n" + "=" * 80)
            logger.info("âœ… æŠ–éŸ³è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ!")
            logger.info("=" * 80)

            return item

        except Exception as e:
            logger.error(f"\nâŒ è·å–æŠ–éŸ³è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            raise

    def _extract_video_info(self, aweme_detail: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»aweme_detailä¸­æå–è§†é¢‘ä¿¡æ¯

        Args:
            aweme_detail: è§†é¢‘è¯¦æƒ…æ•°æ®

        Returns:
            dict: æå–åçš„è§†é¢‘ä¿¡æ¯
        """
        # åŸºæœ¬ä¿¡æ¯
        author = aweme_detail.get("author", {})
        statistics = aweme_detail.get("statistics", {})
        video = aweme_detail.get("video", {})
        music = aweme_detail.get("music", {})

        info = {
            "title": aweme_detail.get("desc", "æ— æ ‡é¢˜"),
            "create_time": aweme_detail.get("create_time"),
            # ä½œè€…ä¿¡æ¯
            "author": {
                "uid": author.get("uid"),
                "sec_uid": author.get("sec_uid"),
                "nickname": author.get("nickname"),
                "signature": author.get("signature"),
                "avatar": author.get("avatar_larger", {}).get("url_list", [None])[0],
            },
            # ç»Ÿè®¡ä¿¡æ¯
            "statistics": {
                "play_count": statistics.get("play_count", 0),
                "digg_count": statistics.get("digg_count", 0),
                "comment_count": statistics.get("comment_count", 0),
                "share_count": statistics.get("share_count", 0),
                "collect_count": statistics.get("collect_count", 0),
            },
            # è§†é¢‘ä¿¡æ¯
            "video": {
                "duration": video.get("duration"),
                "ratio": video.get("ratio"),
                "cover": video.get("cover", {}).get("url_list", [None])[0],
                "dynamic_cover": video.get("dynamic_cover", {}).get("url_list", [None])[
                    0
                ],
                "play_addr": video.get("play_addr", {}).get("url_list", [None])[0],
                "download_addr": video.get("download_addr", {}).get("url_list", [None])[
                    0
                ],
            },
            # éŸ³ä¹ä¿¡æ¯
            "music": {
                "id": music.get("id"),
                "title": music.get("title"),
                "author": music.get("author"),
                "cover": music.get("cover_large", {}).get("url_list", [None])[0],
                "play_url": music.get("play_url", {}).get("url_list", [None])[0],
            },
        }

        return info

    def _format_as_markdown(self, video_info: Dict[str, Any]) -> str:
        """
        å°†è§†é¢‘ä¿¡æ¯æ ¼å¼åŒ–ä¸ºMarkdown

        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸

        Returns:
            str: Markdownæ ¼å¼çš„å†…å®¹
        """
        md_lines = []

        # æ ‡é¢˜
        md_lines.append(f"# {video_info.get('title', 'æŠ–éŸ³è§†é¢‘')}\n")

        # ä½œè€…ä¿¡æ¯
        author = video_info.get("author", {})
        if author:
            md_lines.append(f"**ä½œè€…**: {author.get('nickname', 'N/A')}")
            if author.get("signature"):
                md_lines.append(f"**ç­¾å**: {author.get('signature')}\n")
            else:
                md_lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = video_info.get("statistics", {})
        if stats:
            md_lines.append("## æ•°æ®ç»Ÿè®¡\n")
            md_lines.append(f"- æ’­æ”¾é‡: {stats.get('play_count', 0):,}")
            md_lines.append(f"- ç‚¹èµæ•°: {stats.get('digg_count', 0):,}")
            md_lines.append(f"- è¯„è®ºæ•°: {stats.get('comment_count', 0):,}")
            md_lines.append(f"- åˆ†äº«æ•°: {stats.get('share_count', 0):,}")
            md_lines.append(f"- æ”¶è—æ•°: {stats.get('collect_count', 0):,}\n")

        # è§†é¢‘ä¿¡æ¯
        video = video_info.get("video", {})
        if video:
            md_lines.append("## è§†é¢‘ä¿¡æ¯\n")
            if video.get("duration"):
                md_lines.append(f"- æ—¶é•¿: {video.get('duration')} æ¯«ç§’")
            if video.get("ratio"):
                md_lines.append(f"- æ¯”ä¾‹: {video.get('ratio')}")
            if video.get("cover"):
                md_lines.append(f"\n![å°é¢]({video.get('cover')})\n")

        # éŸ³ä¹ä¿¡æ¯
        music = video_info.get("music", {})
        if music and music.get("title"):
            md_lines.append("## èƒŒæ™¯éŸ³ä¹\n")
            md_lines.append(f"- æ ‡é¢˜: {music.get('title')}")
            if music.get("author"):
                md_lines.append(f"- ä½œè€…: {music.get('author')}\n")

        # é“¾æ¥ä¿¡æ¯
        if video_info.get("complete_url"):
            md_lines.append(f"## é“¾æ¥\n")
            md_lines.append(f"[æŸ¥çœ‹åŸè§†é¢‘]({video_info.get('complete_url')})\n")

        # æœ¬åœ°ä¿å­˜è·¯å¾„
        if video_info.get("local_video_path"):
            md_lines.append(f"**æœ¬åœ°è§†é¢‘**: `{video_info.get('local_video_path')}`\n")

        return "\n".join(md_lines)

    def _format_as_markdown_from_downloader_info(
        self, video_info: Dict[str, Any]
    ) -> str:
        """
        å°†ä¸‹è½½å™¨è¿”å›çš„è§†é¢‘ä¿¡æ¯æ ¼å¼åŒ–ä¸ºMarkdown

        Args:
            video_info: ä¸‹è½½å™¨extract_video_infoè¿”å›çš„è§†é¢‘ä¿¡æ¯å­—å…¸

        Returns:
            str: Markdownæ ¼å¼çš„å†…å®¹
        """
        md_lines = []

        # æ ‡é¢˜
        title = video_info.get("desc", "æŠ–éŸ³è§†é¢‘")
        md_lines.append(f"# {title}\n")

        # ä½œè€…ä¿¡æ¯
        author = video_info.get("author", {})
        if author:
            md_lines.append(f"**ä½œè€…**: {author.get('nickname', 'N/A')}")
            if author.get("unique_id"):
                md_lines.append(f"**æŠ–éŸ³å·**: {author.get('unique_id')}")
            md_lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = video_info.get("statistics", {})
        if stats:
            md_lines.append("## æ•°æ®ç»Ÿè®¡\n")
            md_lines.append(f"- ç‚¹èµæ•°: {stats.get('digg_count', 0):,}")
            md_lines.append(f"- è¯„è®ºæ•°: {stats.get('comment_count', 0):,}")
            md_lines.append(f"- åˆ†äº«æ•°: {stats.get('share_count', 0):,}")
            md_lines.append(f"- æ”¶è—æ•°: {stats.get('collect_count', 0):,}\n")

        # è§†é¢‘ä¿¡æ¯
        video = video_info.get("video", {})
        if video:
            md_lines.append("## è§†é¢‘ä¿¡æ¯\n")
            duration = video.get("duration", 0)
            if duration:
                md_lines.append(f"- æ—¶é•¿: {duration:.1f} ç§’")

            width = video.get("width", 0)
            height = video.get("height", 0)
            if width and height:
                md_lines.append(f"- åˆ†è¾¨ç‡: {width}x{height}")

            if video.get("ratio"):
                md_lines.append(f"- æ¯”ä¾‹: {video.get('ratio')}")

            # æ˜¾ç¤ºå°é¢
            if video.get("cover_url"):
                md_lines.append(f"\n![å°é¢]({video.get('cover_url')})\n")

        # å‘å¸ƒæ—¶é—´
        create_time = video_info.get("create_time")
        if create_time:
            from datetime import datetime

            dt = datetime.fromtimestamp(create_time)
            md_lines.append(f"**å‘å¸ƒæ—¶é—´**: {dt.strftime('%Y-%m-%d %H:%M:%S')}\n")

        # é“¾æ¥ä¿¡æ¯
        if video_info.get("complete_url"):
            md_lines.append(f"## é“¾æ¥\n")
            md_lines.append(f"[æŸ¥çœ‹åŸè§†é¢‘]({video_info.get('complete_url')})\n")

        # æœ¬åœ°ä¿å­˜è·¯å¾„
        if video_info.get("local_video_path"):
            md_lines.append(f"**æœ¬åœ°è§†é¢‘**: `{video_info.get('local_video_path')}`\n")

        # æ¸…æ™°åº¦é€‰é¡¹
        quality_urls = video.get("quality_urls", {})
        if quality_urls:
            md_lines.append("## å¯ç”¨æ¸…æ™°åº¦\n")
            for quality, url in quality_urls.items():
                md_lines.append(f"- {quality}")
            md_lines.append("")

        return "\n".join(md_lines)

    def _format_video_info_text(self, video_info: Dict[str, Any]) -> str:
        """
        å°†è§†é¢‘ä¿¡æ¯æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬

        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸

        Returns:
            str: çº¯æ–‡æœ¬æ ¼å¼çš„å†…å®¹
        """
        lines = []

        # åŸºæœ¬ä¿¡æ¯
        lines.append(f"æ ‡é¢˜: {video_info.get('desc', 'æ— æ ‡é¢˜')}")
        lines.append(f"ä½œå“ID: {video_info.get('aweme_id', 'N/A')}")

        # ä½œè€…ä¿¡æ¯
        author = video_info.get("author", {})
        if author:
            lines.append(f"ä½œè€…: {author.get('nickname', 'N/A')}")
            if author.get("unique_id"):
                lines.append(f"æŠ–éŸ³å·: {author.get('unique_id')}")

        # è§†é¢‘ä¿¡æ¯
        video = video_info.get("video", {})
        if video:
            duration = video.get("duration", 0)
            if duration:
                lines.append(f"æ—¶é•¿: {duration:.1f}ç§’")

            width = video.get("width", 0)
            height = video.get("height", 0)
            if width and height:
                lines.append(f"åˆ†è¾¨ç‡: {width}x{height}")

        # ç»Ÿè®¡æ•°æ®
        stats = video_info.get("statistics", {})
        if stats:
            lines.append(f"ç‚¹èµ: {stats.get('digg_count', 0):,}")
            lines.append(f"è¯„è®º: {stats.get('comment_count', 0):,}")
            lines.append(f"åˆ†äº«: {stats.get('share_count', 0):,}")
            lines.append(f"æ”¶è—: {stats.get('collect_count', 0):,}")

        # å‘å¸ƒæ—¶é—´
        create_time = video_info.get("create_time")
        if create_time:
            dt = datetime.fromtimestamp(create_time)
            lines.append(f"å‘å¸ƒæ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M:%S')}")

        return "\n".join(lines)

    async def close(self):
        """å…³é—­è¿æ¥"""
        if hasattr(self.downloader, "client"):
            await self.downloader.client.aclose()
