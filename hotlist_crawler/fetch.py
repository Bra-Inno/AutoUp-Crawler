import os
import asyncio
from loguru import logger
from typing import Optional

from hotlist_crawler.providers.zhihu import ZhihuArticleProvider
from hotlist_crawler.providers.weibo import WeiboProvider
from hotlist_crawler.providers.weixin import WeixinMpProvider
from hotlist_crawler.providers.bilibili import BilibiliVideoProvider, BilibiliVideoQuality
from hotlist_crawler.providers.xhs import XiaohongshuProvider
from hotlist_crawler.providers.douyin import DouyinVideoProvider
from hotlist_crawler.config import settings
from hotlist_crawler.storage import storage_manager


def identify_platform_from_url(url: str) -> Optional[str]:
    """æ ¹æ®URLè‡ªåŠ¨è¯†åˆ«å¹³å°ç±»å‹"""
    from urllib.parse import urlparse

    # æ£€æŸ¥æ˜¯å¦æ˜¯å°çº¢ä¹¦å…³é”®è¯æœç´¢æ ¼å¼
    if url.startswith("xhs_keyword:"):
        return "xiaohongshu"

    domain = urlparse(url).netloc

    for platform, config in settings.PLATFORMS.items():
        if any(d in domain for d in config["domains"]):
            return platform
    return None


def fetch(
    url: str,
    destination: str,
    cookies: list | str | None = None,
    save_images: bool = True,
    output_format: str = "markdown",
    max_answers: int = 3,
) -> bool:
    """åŒæ­¥ç‰ˆæœ¬çš„fetchå®ç°"""
    try:
        # 1. è¯†åˆ«å¹³å°
        platform = identify_platform_from_url(url)
        if not platform:
            logger.error(f"âŒ æ— æ³•è¯†åˆ«å¹³å°: {url}")
            return False

        logger.info(f"ğŸ¯ è¯†åˆ«å¹³å°: {platform}")

        # 2. ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        destination = os.path.abspath(destination)
        os.makedirs(destination, exist_ok=True)
        logger.info(f"ğŸ“ ç›®æ ‡ç›®å½•: {destination}")

        # 3. ä¸´æ—¶ä¿®æ”¹å­˜å‚¨ç®¡ç†å™¨çš„åŸºç¡€ç›®å½•
        original_base_dir = storage_manager.base_dir
        storage_manager.base_dir = destination

        provider = None
        result = None

        try:
            # 4. æ ¹æ®å¹³å°åˆ›å»ºå¯¹åº”çš„æä¾›è€…
            if platform == "zhihu":
                provider = ZhihuArticleProvider(
                    url=url,
                    rules=settings.PLATFORMS[platform]["rules"],
                    save_images=save_images,
                    output_format=output_format,
                    cookies=cookies,
                    force_save=True,
                    max_answers=max_answers,
                )
            elif platform == "weibo":
                provider = WeiboProvider(
                    url=url,
                    rules=settings.PLATFORMS[platform]["rules"],
                    save_images=save_images,
                    output_format=output_format,
                    cookies=cookies,
                    force_save=True,
                )
            elif platform == "weixin":
                provider = WeixinMpProvider(
                    url=url,
                    rules=settings.PLATFORMS[platform]["rules"],
                    save_images=save_images,
                    output_format=output_format,
                    cookies=cookies,
                    force_save=True,
                )
            elif platform == "bilibili":
                provider = BilibiliVideoProvider(
                    url=url,
                    rules={},  # Bç«™ä¸éœ€è¦rules
                    save_images=save_images,
                    output_format=output_format,
                    force_save=True,
                    cookies=cookies,
                    auto_download_video=True,
                    video_quality=BilibiliVideoQuality.QUALITY_1080P,  # é»˜è®¤1080P
                )
            elif platform == "douyin":
                provider = DouyinVideoProvider(
                    url=url,
                    rules={},  # æŠ–éŸ³ä¸éœ€è¦rules
                    save_images=save_images,
                    output_format=output_format,
                    cookies=cookies,
                    force_save=True,
                    auto_download_video=True,  # é»˜è®¤è‡ªåŠ¨ä¸‹è½½è§†é¢‘
                )
            elif platform == "xiaohongshu":
                if url.startswith("xhs_keyword:"):
                    keyword = url.replace("xhs_keyword:", "").strip()
                    if not keyword:
                        logger.error(f"âŒ å°çº¢ä¹¦å…³é”®è¯ä¸èƒ½ä¸ºç©º")
                        return False

                    logger.debug(f"ğŸ” å°çº¢ä¹¦å…³é”®è¯æœç´¢: {keyword}")
                    if cookies is None:
                        logger.error(f"âŒ å°çº¢ä¹¦æœç´¢éœ€è¦æœ‰æ•ˆçš„cookiesï¼Œè¯·æä¾›cookieså‚æ•°")
                        logger.info(f"ğŸ’¡ æç¤º: ä½¿ç”¨ cookies å‚æ•°æä¾›å°çº¢ä¹¦ç™»å½•cookies")
                        return False
                    provider = XiaohongshuProvider(cookies=cookies, save_dir=destination)

                    # --- å¼‚æ­¥è¾…åŠ©å‡½æ•° (å°çº¢ä¹¦) ---
                    async def _run_xhs_search():
                        search_result = await provider.search_and_save(
                            query=keyword,
                            require_num=2,
                            save_format="both",
                            custom_save_dir=destination,
                        )
                        await provider.close()
                        return search_result

                    # ä½¿ç”¨ asyncio.run() åŒæ­¥æ‰§è¡Œ
                    result = asyncio.run(_run_xhs_search())

                    if result.get("success"):
                        logger.info(f"âœ… å°çº¢ä¹¦æœç´¢æˆåŠŸï¼")
                        logger.debug(f"ğŸ“Š æ‰¾åˆ° {result['total_found']} ä¸ªç¬”è®°")
                        logger.info(f"ğŸ’¾ æˆåŠŸä¿å­˜ {result['saved']} ä¸ªç¬”è®°")
                        logger.info(f"ğŸ“‚ ä¿å­˜ä½ç½®: {result['save_directory']}")
                        return True
                    else:
                        error_msg = result.get("error") or result.get("statistics", {}).get("error", "æœªçŸ¥é”™è¯¯")
                        logger.error(f"âŒ å°çº¢ä¹¦æœç´¢å¤±è´¥: {error_msg}")
                        return False
                else:
                    logger.warning(f"âš ï¸ å°çº¢ä¹¦ç¬”è®°URLæŠ“å–æš‚æœªå®ç°")
                    logger.info(f"ğŸ’¡ è¯·ä½¿ç”¨æ ¼å¼: xhs_keyword:å…³é”®è¯")
                    return False
            else:
                logger.error(f"âŒ å¹³å° '{platform}' çš„æŠ“å–é€»è¾‘æœªå®ç°")
                return False

            # 5. æ‰§è¡ŒæŠ“å– (é€‚ç”¨äºé™¤å°çº¢ä¹¦å…³é”®è¯æœç´¢å¤–çš„æ‰€æœ‰å¹³å°)
            logger.info(f"ğŸš€ å¼€å§‹æŠ“å–: {url}")

            # --- å¼‚æ­¥è¾…åŠ©å‡½æ•° (å…¶ä»–å¹³å°) ---
            async def _run_fetch():
                return await provider.fetch_and_parse()

            # ä½¿ç”¨ asyncio.run() åŒæ­¥æ‰§è¡Œ
            result = asyncio.run(_run_fetch())

            if result is None:
                logger.error(f"âŒ æŠ“å–å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°å†…å®¹")
                return False

            # 6. éªŒè¯æ–‡ä»¶æ˜¯å¦ä¿å­˜æˆåŠŸ (åŒæ­¥)
            platform_dir = os.path.join(destination, platform)
            if os.path.exists(platform_dir) and os.listdir(platform_dir):
                logger.info(f"âœ… æŠ“å–æˆåŠŸï¼è·å–åˆ°å†…å®¹é¡¹")
                logger.info(f"ğŸ“‚ æ–‡ä»¶å·²ä¿å­˜åˆ°: {platform_dir}")

                if hasattr(result, "title") and result.title:
                    logger.debug(f"   ğŸ“„ {result.title}")
                return True
            else:
                logger.warning(f"âš ï¸ æŠ“å–å®Œæˆä½†æ–‡ä»¶ä¿å­˜éªŒè¯å¤±è´¥")
                return False

        finally:
            # æ¢å¤åŸå§‹åŸºç¡€ç›®å½• (åŒæ­¥)
            storage_manager.base_dir = original_base_dir

    except Exception as e:
        logger.error(f"âŒ æŠ“å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
