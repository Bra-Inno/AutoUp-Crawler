import re
import os
import json
import asyncio
from loguru import logger
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime
from playwright.async_api import async_playwright

from .base import BaseProvider
from ..models import ScrapedDataItem
from ..storage import storage_manager
from ..utils.dy import DouyinVideoDownloader
from ..file_utils import get_random_user_agent, format_cookies_to_string


class DouyinVideoProvider(BaseProvider):
    """
    æŠ–éŸ³è§†é¢‘Provider

    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. æ”¯æŒä¸å®Œæ•´é“¾æ¥ï¼ˆåªæœ‰è§†é¢‘IDï¼‰è‡ªåŠ¨è·å–ç”¨æˆ·ID
    2. ä½¿ç”¨Playwrightæµè§ˆå™¨è‡ªåŠ¨åŒ–æŠ€æœ¯
    3. è‡ªåŠ¨ä¸‹è½½è§†é¢‘åˆ°æŒ‡å®šç›®å½•
    4. æå–å®Œæ•´çš„è§†é¢‘ä¿¡æ¯
    5. è‡ªåŠ¨ä»æµè§ˆå™¨æ•°æ®åŠ è½½Cookieå’ŒUser-Agent
    """

    def __init__(
        self,
        url: str,
        rules: dict | None = None,
        save_images: bool = False,
        output_format: str = "markdown",
        cookies: list | str | None = None,
        force_save: bool = True,
        auto_download_video: bool = False,
    ):
        """
        åˆå§‹åŒ–æŠ–éŸ³è§†é¢‘Provider

        Args:
            url: æŠ–éŸ³è§†é¢‘URLï¼ˆæ”¯æŒä¸å®Œæ•´é“¾æ¥ï¼‰
            rules: è§„åˆ™é…ç½®ï¼ˆä¿æŒæ¥å£ä¸€è‡´ï¼‰
            save_images: æ˜¯å¦ä¿å­˜å›¾ç‰‡
            output_format: è¾“å‡ºæ ¼å¼
            force_save: æ˜¯å¦å¼ºåˆ¶ä¿å­˜
            cookies: Cookieå­—ç¬¦ä¸²ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»æµè§ˆå™¨æ•°æ®åŠ è½½ï¼‰
            auto_download_video: æ˜¯å¦è‡ªåŠ¨ä¸‹è½½è§†é¢‘
        """
        if rules is None:
            rules = {}
        super().__init__(url, rules, save_images, output_format, force_save, "douyin")

        self.url = url
        self.auto_download_video = auto_download_video

        # åŠ è½½Cookieå’ŒUser-Agent
        self.cookies = format_cookies_to_string(cookies)
        self.user_agent = get_random_user_agent()

        # åˆå§‹åŒ–ä¸‹è½½å™¨ï¼ˆä½¿ç”¨åŠ è½½çš„Cookieå’ŒUAï¼‰
        self.downloader = DouyinVideoDownloader(cookie=self.cookies or "", user_agent=self.user_agent)

    async def _get_user_id_from_browser(self, video_url: str) -> Optional[str]:
        """
        ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–è·å–ç”¨æˆ·ID

        Args:
            video_url: è§†é¢‘URL

        Returns:
            str: ç”¨æˆ·IDï¼Œå¤±è´¥è¿”å›None
        """
        logger.debug(f"   ğŸŒ ä½¿ç”¨æµè§ˆå™¨è·å–ç”¨æˆ·ID...")

        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True)
                context = await browser.new_context(user_agent=self.user_agent)
                page = await context.new_page()

                try:
                    logger.debug("   â³ æ­£åœ¨åŠ è½½é¡µé¢...")
                    await page.goto(video_url, wait_until="networkidle", timeout=30000)
                    await asyncio.sleep(3)

                    html_content = await page.content()
                    pattern = r"https://www\.douyin\.com/user/([A-Za-z0-9_-]+)"
                    matches = re.findall(pattern, html_content)

                    if matches:
                        user_id = matches[0]
                        logger.debug(f"   âœ… æˆåŠŸè·å–ç”¨æˆ·ID: {user_id[:30]}...")
                        return user_id
                    else:
                        logger.error("   âŒ æœªåœ¨ç½‘é¡µä¸­æ‰¾åˆ°ç”¨æˆ·ID")
                        return None
                except Exception as e:
                    logger.error(f"   âŒ è·å–å¤±è´¥: {e}")
                    return None
                finally:
                    await browser.close()
        except Exception as e:
            logger.error(f"   âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return None

    async def _build_complete_url(self, url: str) -> Optional[str]:
        """
        å°†ä¸å®Œæ•´é“¾æ¥è½¬æ¢ä¸ºå®Œæ•´é“¾æ¥

        Args:
            url: åŸå§‹URLï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰

        Returns:
            str: å®Œæ•´çš„URLï¼Œå¤±è´¥è¿”å›None
        """
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´é“¾æ¥ï¼Œç›´æ¥è¿”å›
        if "/user/" in url:
            logger.debug("   âœ… å·²ç»æ˜¯å®Œæ•´é“¾æ¥")
            return url

        # æå–è§†é¢‘ID
        video_id_match = re.search(r"/video/(\d+)", url)
        if not video_id_match:
            logger.error("   âŒ æ— æ³•ä»é“¾æ¥ä¸­æå–è§†é¢‘ID")
            return None

        video_id = video_id_match.group(1)
        logger.debug(f"   ğŸ“¹ è§†é¢‘ID: {video_id}")

        # ä½¿ç”¨æµè§ˆå™¨è·å–ç”¨æˆ·ID
        user_id = await self._get_user_id_from_browser(url)
        if not user_id:
            return None

        # æ‹¼æ¥å®Œæ•´é“¾æ¥
        complete_url = f"https://www.douyin.com/user/{user_id}/video/{video_id}"
        logger.debug(f"   âœ… å®Œæ•´é“¾æ¥: {complete_url[:80]}...")
        return complete_url

    async def fetch_and_parse(self) -> ScrapedDataItem:
        """
        è·å–å¹¶è§£ææŠ–éŸ³è§†é¢‘ä¿¡æ¯

        Returns:
            ScrapedDataItem: åŒ…å«è§†é¢‘ä¿¡æ¯çš„æ•°æ®é¡¹
        """
        try:
            logger.debug("\n" + "=" * 80 + "\nğŸ¬ æŠ–éŸ³è§†é¢‘Provider - å¼€å§‹å¤„ç†\n" + "=" * 80)
            logger.debug(f"\nğŸ“ è¾“å…¥é“¾æ¥: {self.url}")

            # 1. å¤„ç†é“¾æ¥ï¼ˆå¦‚æœéœ€è¦è¡¥å…¨ï¼‰
            logger.debug("\nğŸ”§ æ­£åœ¨å¤„ç†é“¾æ¥...")
            complete_url = await self._build_complete_url(self.url)

            if not complete_url:
                raise Exception("æ— æ³•è·å–å®Œæ•´é“¾æ¥")

            # 2. è§£æURLè·å–è§†é¢‘IDå’Œç”¨æˆ·ID
            logger.debug("\nğŸ” æ­£åœ¨è§£ææŠ–éŸ³é“¾æ¥...")
            parse_result = await self.downloader.parse_share_url(complete_url)

            if not parse_result or "aweme_id" not in parse_result:
                raise Exception("æ— æ³•è§£æè§†é¢‘é“¾æ¥")

            aweme_id = parse_result["aweme_id"]
            sec_user_id = parse_result.get("sec_user_id")

            logger.info(f"   âœ… è§£ææˆåŠŸ!")
            logger.info(f"   ä½œå“ID: {aweme_id}")
            if sec_user_id:
                logger.info(f"   ç”¨æˆ·ID: {sec_user_id[:20]}...")

            # 3. ä»ç”¨æˆ·ä½œå“åˆ—è¡¨ä¸­æŸ¥æ‰¾è§†é¢‘ï¼ˆæ›´å¯é çš„æ–¹æ³•ï¼‰
            aweme = None
            if sec_user_id:
                logger.info("\nï¿½ ä»ç”¨æˆ·ä½œå“åˆ—è¡¨ä¸­æŸ¥æ‰¾è§†é¢‘...")
                aweme = await self.downloader.find_video_in_posts(sec_user_id, aweme_id)

            # å¦‚æœfind_video_in_postså¤±è´¥ï¼Œå›é€€åˆ°ç›´æ¥è·å–è¯¦æƒ…
            if not aweme:
                logger.info("\nğŸ“¥ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–è§†é¢‘è¯¦æƒ…...")
                aweme = await self.downloader.fetch_aweme_detail(aweme_id)

            if not aweme:
                raise Exception("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")

            # 4. æå–è§†é¢‘ä¿¡æ¯
            video_info = self.downloader.extract_video_info(aweme)
            video_info["complete_url"] = complete_url

            # æ‰“å°è§†é¢‘ä¿¡æ¯
            self.downloader.print_video_info(video_info)

            # 5. åˆ›å»ºå­˜å‚¨ç›®å½•ï¼ˆå¦‚æœéœ€è¦ä¿å­˜ï¼‰
            storage_info = None
            if self.force_save:
                storage_info = storage_manager.create_article_storage(
                    platform=self.platform_name,
                    title=video_info.get("desc", "æŠ–éŸ³è§†é¢‘"),
                    url=self.url,
                )

            # 6. è‡ªåŠ¨ä¸‹è½½è§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.auto_download_video and storage_info:
                logger.info(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘...")

                # è·å–è§†é¢‘ä¸‹è½½åœ°å€
                video_url = video_info["video"].get("download_url") or video_info["video"].get("play_url")

                if not video_url:
                    logger.warning("   âš ï¸ æœªæ‰¾åˆ°è§†é¢‘ä¸‹è½½åœ°å€")
                else:
                    # æ„é€ æ–‡ä»¶å
                    author_name = video_info["author"]["nickname"]
                    desc = video_info["desc"][:30]

                    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                    safe_author = re.sub(r'[<>:"/\\|?*]', "_", author_name)
                    safe_desc = re.sub(r'[<>:"/\\|?*]', "_", desc)

                    filename = f"{safe_author}_{aweme_id}_{safe_desc}.mp4"
                    save_path = os.path.join(storage_info["article_dir"], filename)

                    # ä¸‹è½½è§†é¢‘
                    success = await self.downloader.download_video(video_url, save_path)

                    if success:
                        video_info["local_video_path"] = save_path
                        # è·å–æ–‡ä»¶å¤§å°
                        file_size = Path(save_path).stat().st_size / (1024 * 1024)
                        logger.info(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                    else:
                        logger.error(f"   âš ï¸ è§†é¢‘ä¸‹è½½å¤±è´¥")

            # 7. åˆ›å»ºScrapedDataItem
            title = video_info.get("desc", "æŠ–éŸ³è§†é¢‘")
            author_name = video_info.get("author", {}).get("nickname", "æœªçŸ¥ä½œè€…")

            # æ ¼å¼åŒ–å†…å®¹æ–‡æœ¬
            content_text = self._format_video_info_text(video_info)
            markdown_content = self._format_as_markdown_from_downloader_info(video_info)

            # 8. ä¿å­˜åˆ°æœ¬åœ°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.force_save and storage_info:
                # ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´æ•°æ®
                json_path = os.path.join(storage_info["article_dir"], "video_info.json")
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(video_info, f, ensure_ascii=False, indent=2)

                # ä¿å­˜æ–‡æœ¬å†…å®¹
                storage_manager.save_text_content(storage_info, content_text)

                # ä¿å­˜markdownæ ¼å¼
                storage_manager.save_markdown_content(storage_info, markdown_content, title)

                # ä¿å­˜æ–‡ç« ç´¢å¼•
                storage_manager.save_article_index(storage_info, video_info.get("desc", "")[:200])

            item = ScrapedDataItem(
                title=title,
                author=author_name,
                content=content_text,
                markdown_content=markdown_content,
                images=[],
                save_directory=(storage_info.get("article_dir") if storage_info else None),
            )

            logger.info("\n" + "=" * 80)
            logger.info("âœ… æŠ–éŸ³è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ!")
            logger.info("=" * 80)

            return item

        except Exception as e:
            logger.error(f"\nâŒ è·å–æŠ–éŸ³è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
            raise

    def _format_as_markdown_from_downloader_info(self, video_info: Dict[str, Any]) -> str:
        """
        å°†ä¸‹è½½å™¨è¿”å›çš„è§†é¢‘ä¿¡æ¯æ ¼å¼åŒ–ä¸ºMarkdown

        Args:
            video_info: ä¸‹è½½å™¨extract_video_infoè¿”å›çš„è§†é¢‘ä¿¡æ¯å­—å…¸

        Returns:
            str: Markdownæ ¼å¼çš„å†…å®¹
        """
        md_lines = []

        # æ ‡é¢˜
        title = video_info.get("desc", "æŠ–éŸ³è§†é¢‘")
        md_lines.append(f"# {title}\n")

        # ä½œè€…ä¿¡æ¯
        author = video_info.get("author", {})
        if author:
            md_lines.append(f"**ä½œè€…**: {author.get('nickname', 'N/A')}")
            if author.get("unique_id"):
                md_lines.append(f"**æŠ–éŸ³å·**: {author.get('unique_id')}")
            md_lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = video_info.get("statistics", {})
        if stats:
            md_lines.append("## æ•°æ®ç»Ÿè®¡\n")
            md_lines.append(f"- ç‚¹èµæ•°: {stats.get('digg_count', 0):,}")
            md_lines.append(f"- è¯„è®ºæ•°: {stats.get('comment_count', 0):,}")
            md_lines.append(f"- åˆ†äº«æ•°: {stats.get('share_count', 0):,}")
            md_lines.append(f"- æ”¶è—æ•°: {stats.get('collect_count', 0):,}\n")

        # è§†é¢‘ä¿¡æ¯
        video = video_info.get("video", {})
        if video:
            md_lines.append("## è§†é¢‘ä¿¡æ¯\n")
            duration = video.get("duration", 0)
            if duration:
                md_lines.append(f"- æ—¶é•¿: {duration:.1f} ç§’")

            width = video.get("width", 0)
            height = video.get("height", 0)
            if width and height:
                md_lines.append(f"- åˆ†è¾¨ç‡: {width}x{height}")

            if video.get("ratio"):
                md_lines.append(f"- æ¯”ä¾‹: {video.get('ratio')}")

            # æ˜¾ç¤ºå°é¢
            if video.get("cover_url"):
                md_lines.append(f"\n![å°é¢]({video.get('cover_url')})\n")

        # å‘å¸ƒæ—¶é—´
        create_time = video_info.get("create_time")
        if create_time:
            dt = datetime.fromtimestamp(create_time)
            md_lines.append(f"**å‘å¸ƒæ—¶é—´**: {dt.strftime('%Y-%m-%d %H:%M:%S')}\n")

        # é“¾æ¥ä¿¡æ¯
        if video_info.get("complete_url"):
            md_lines.append(f"## é“¾æ¥\n")
            md_lines.append(f"[æŸ¥çœ‹åŸè§†é¢‘]({video_info.get('complete_url')})\n")

        # æœ¬åœ°ä¿å­˜è·¯å¾„
        if video_info.get("local_video_path"):
            md_lines.append(f"**æœ¬åœ°è§†é¢‘**: `{video_info.get('local_video_path')}`\n")

        # æ¸…æ™°åº¦é€‰é¡¹
        quality_urls = video.get("quality_urls", {})
        if quality_urls:
            md_lines.append("## å¯ç”¨æ¸…æ™°åº¦\n")
            for quality, url in quality_urls.items():
                md_lines.append(f"- {quality}")
            md_lines.append("")

        return "\n".join(md_lines)

    def _format_video_info_text(self, video_info: Dict[str, Any]) -> str:
        """
        å°†è§†é¢‘ä¿¡æ¯æ ¼å¼åŒ–ä¸ºçº¯æ–‡æœ¬

        Args:
            video_info: è§†é¢‘ä¿¡æ¯å­—å…¸

        Returns:
            str: çº¯æ–‡æœ¬æ ¼å¼çš„å†…å®¹
        """
        lines = []

        # åŸºæœ¬ä¿¡æ¯
        lines.append(f"æ ‡é¢˜: {video_info.get('desc', 'æ— æ ‡é¢˜')}")
        lines.append(f"ä½œå“ID: {video_info.get('aweme_id', 'N/A')}")

        # ä½œè€…ä¿¡æ¯
        author = video_info.get("author", {})
        if author:
            lines.append(f"ä½œè€…: {author.get('nickname', 'N/A')}")
            if author.get("unique_id"):
                lines.append(f"æŠ–éŸ³å·: {author.get('unique_id')}")

        # è§†é¢‘ä¿¡æ¯
        video = video_info.get("video", {})
        if video:
            duration = video.get("duration", 0)
            if duration:
                lines.append(f"æ—¶é•¿: {duration:.1f}ç§’")

            width = video.get("width", 0)
            height = video.get("height", 0)
            if width and height:
                lines.append(f"åˆ†è¾¨ç‡: {width}x{height}")

        # ç»Ÿè®¡æ•°æ®
        stats = video_info.get("statistics", {})
        if stats:
            lines.append(f"ç‚¹èµ: {stats.get('digg_count', 0):,}")
            lines.append(f"è¯„è®º: {stats.get('comment_count', 0):,}")
            lines.append(f"åˆ†äº«: {stats.get('share_count', 0):,}")
            lines.append(f"æ”¶è—: {stats.get('collect_count', 0):,}")

        # å‘å¸ƒæ—¶é—´
        create_time = video_info.get("create_time")
        if create_time:
            dt = datetime.fromtimestamp(create_time)
            lines.append(f"å‘å¸ƒæ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M:%S')}")

        return "\n".join(lines)

    async def close(self):
        """å…³é—­è¿æ¥"""
        if hasattr(self.downloader, "client"):
            await self.downloader.client.aclose()
