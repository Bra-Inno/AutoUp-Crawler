import asyncio
import httpx
import re
import os
import json
from pathlib import Path
from urllib.parse import urlencode
from typing import Dict, Any, Optional
from datetime import datetime
from loguru import logger


class DouyinVideoDownloader:
    """æŠ–éŸ³è§†é¢‘ä¸‹è½½å™¨"""

    USER_POST_ENDPOINT = "https://www.douyin.com/aweme/v1/web/aweme/post/"
    AWEME_DETAIL_ENDPOINT = "https://www.douyin.com/aweme/v1/web/aweme/detail/"

    def __init__(self, cookie: str = "", user_agent: str = ""):
        """åˆå§‹åŒ–ä¸‹è½½å™¨ï¼Œæ¥æ”¶é…ç½®å‚æ•°ã€‚"""
        self.cookie = cookie
        self.user_agent = user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        self.headers = {
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "User-Agent": self.user_agent,
            "Referer": "https://www.douyin.com/",
            "Cookie": self.cookie,
        }
        self.client = httpx.AsyncClient(headers=self.headers, timeout=30.0, follow_redirects=True, http2=True)

    async def parse_share_url(self, share_url: str) -> Dict[str, Optional[str]]:
        """è§£æåˆ†äº«é“¾æ¥ï¼Œè·å–ä½œå“IDå’Œç”¨æˆ·IDã€‚"""
        logger.debug(f"ğŸ” æ­£åœ¨è§£æé“¾æ¥...")

        try:
            if "v.douyin.com" in share_url or "iesdouyin.com" in share_url:
                async with httpx.AsyncClient(follow_redirects=True, timeout=10) as client:
                    response = await client.get(share_url)
                    share_url = str(response.url)

            aweme_id = None
            sec_user_id = None

            video_match = re.search(r"/video/(\d+)", share_url)
            if video_match:
                aweme_id = video_match.group(1)

            user_match = re.search(r"/user/([^/\?]+)", share_url)
            if user_match:
                sec_user_id = user_match.group(1)

            if not aweme_id:
                modal_match = re.search(r"modal_id=(\d+)", share_url)
                if modal_match:
                    aweme_id = modal_match.group(1)

            if aweme_id and not sec_user_id:
                logger.debug(f"âš ï¸  é“¾æ¥ç¼ºå°‘ç”¨æˆ·IDï¼Œå°è¯•è‡ªåŠ¨è·å–...")
                sec_user_id = await self._fetch_user_id_from_video(aweme_id)

            if aweme_id:
                logger.info(f"âœ… è§£ææˆåŠŸ! ä½œå“ID: {aweme_id}")

            return {"aweme_id": aweme_id, "sec_user_id": sec_user_id, "url": share_url}

        except Exception as e:
            logger.error(f"âŒ è§£æé“¾æ¥å¤±è´¥: {e}")
            return {}

    async def _fetch_user_id_from_video(self, aweme_id: str) -> Optional[str]:
        """ä»è§†é¢‘IDè·å–ç”¨æˆ·IDã€‚"""
        try:
            video_url = f"https://www.douyin.com/video/{aweme_id}"
            response = await self.client.get(video_url, follow_redirects=True)

            user_match = re.search(r"/user/([^/\?]+)", str(response.url))
            if user_match:
                return user_match.group(1)

            html = response.text
            sec_id_match = re.search(r'"authorSecId"\s*:\s*"([^"]+)"', html)
            if sec_id_match:
                return sec_id_match.group(1)

        except Exception as e:
            logger.debug(f"è·å–ç”¨æˆ·IDå¤±è´¥: {e}")

        return None

    async def fetch_aweme_detail(self, aweme_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä½œå“è¯¦æƒ…ã€‚"""
        params = {
            "device_platform": "webapp",
            "aid": "6383",
            "channel": "channel_pc_web",
            "aweme_id": aweme_id,
            "pc_client_type": 1,
            "version_code": "290100",
            "version_name": "29.1.0",
            "cookie_enabled": "true",
            "screen_width": 1920,
            "screen_height": 1080,
            "browser_language": "zh-CN",
            "browser_platform": "Win32",
            "browser_name": "Chrome",
            "browser_version": "130.0.0.0",
        }

        url = f"{self.AWEME_DETAIL_ENDPOINT}?{urlencode(params)}"

        try:
            response = await self.client.get(url)
            data = response.json()

            if data.get("status_code") == 0:
                aweme_detail = data.get("aweme_detail")
                if aweme_detail:
                    return aweme_detail

        except Exception as e:
            logger.debug(f"è·å–ä½œå“è¯¦æƒ…å¤±è´¥: {e}")

        return None

    def extract_video_info(self, aweme: Dict[str, Any]) -> Dict[str, Any]:
        """ä»ä½œå“æ•°æ®ä¸­æå–è§†é¢‘ä¿¡æ¯ã€‚"""
        video = aweme.get("video", {})
        author = aweme.get("author", {})
        statistics = aweme.get("statistics", {})

        play_addr = video.get("play_addr", {}).get("url_list", [])
        download_addr = video.get("download_addr", {}).get("url_list", [])

        return {
            "aweme_id": aweme.get("aweme_id"),
            "desc": aweme.get("desc", ""),
            "create_time": aweme.get("create_time", 0),
            "author": {
                "nickname": author.get("nickname", ""),
                "unique_id": author.get("unique_id", ""),
                "sec_uid": author.get("sec_uid", ""),
            },
            "video": {
                "duration": video.get("duration", 0) / 1000,
                "width": video.get("width", 0),
                "height": video.get("height", 0),
                "cover_url": video.get("cover", {}).get("url_list", [""])[0],
                "play_url": play_addr[0] if play_addr else "",
                "download_url": download_addr[0] if download_addr else "",
            },
            "statistics": {
                "digg_count": statistics.get("digg_count", 0),
                "comment_count": statistics.get("comment_count", 0),
                "share_count": statistics.get("share_count", 0),
                "collect_count": statistics.get("collect_count", 0),
            },
        }

    def print_video_info(self, info: Dict[str, Any]):
        """æ‰“å°è§†é¢‘ä¿¡æ¯ã€‚"""
        logger.info("ğŸ“¹ è§†é¢‘ä¿¡æ¯")
        logger.info(f"   ä½œå“ID: {info['aweme_id']}")
        logger.info(f"   æè¿°: {info['desc'][:60]}")

        if info["create_time"]:
            dt = datetime.fromtimestamp(info["create_time"])
            logger.info(f"   å‘å¸ƒæ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M:%S')}")

        author = info["author"]
        logger.info(f"ğŸ‘¤ ä½œè€…: {author['nickname']}")

        video = info["video"]
        logger.info(f"ğŸ¬ è§†é¢‘: {video['duration']:.1f}ç§’, {video['width']}x{video['height']}")

        stats = info["statistics"]
        logger.info(f"ğŸ“Š ç‚¹èµ: {stats['digg_count']}, è¯„è®º: {stats['comment_count']}")

    async def download_video(self, video_url: str, save_path: str) -> bool:
        """ä¸‹è½½è§†é¢‘åˆ°æŒ‡å®šè·¯å¾„ã€‚"""
        try:
            logger.info(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½è§†é¢‘...")

            Path(save_path).parent.mkdir(parents=True, exist_ok=True)

            async with httpx.AsyncClient(timeout=300.0) as client:
                async with client.stream(
                    "GET",
                    video_url,
                    headers={
                        "User-Agent": self.user_agent,
                        "Referer": "https://www.douyin.com/",
                    },
                ) as response:
                    response.raise_for_status()

                    total_size = int(response.headers.get("content-length", 0))
                    downloaded = 0

                    with open(save_path, "wb") as f:
                        async for chunk in response.aiter_bytes(chunk_size=1024 * 1024):
                            f.write(chunk)
                            downloaded += len(chunk)

                            if total_size > 0:
                                progress = (downloaded / total_size) * 100
                                logger.debug(f"è¿›åº¦: {progress:.1f}%")

            logger.info(f"âœ… ä¸‹è½½å®Œæˆ! ä¿å­˜è·¯å¾„: {save_path}")
            return True

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False

    async def download_from_url(self, share_url: str, save_dir: str = "downloads") -> str:
        """ä»åˆ†äº«é“¾æ¥ä¸‹è½½è§†é¢‘ï¼Œè¿”å›ä¿å­˜è·¯å¾„ã€‚"""
        parse_result = await self.parse_share_url(share_url)
        aweme_id = parse_result.get("aweme_id")

        if not aweme_id:
            logger.error("âŒ æ— æ³•ä»é“¾æ¥ä¸­æå–ä½œå“ID")
            return ""

        aweme = await self.fetch_aweme_detail(aweme_id)
        if not aweme:
            logger.error("âŒ æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
            return ""

        video_info = self.extract_video_info(aweme)
        self.print_video_info(video_info)

        video_data = video_info["video"]
        download_url = video_data.get("download_url") or video_data.get("play_url")

        if not download_url:
            logger.error("âŒ æœªæ‰¾åˆ°è§†é¢‘ä¸‹è½½åœ°å€")
            return ""

        author_name = video_info["author"]["nickname"]
        desc = video_info["desc"][:30]
        safe_author = re.sub(r'[<>:"/\\|?*]', "_", author_name)
        safe_desc = re.sub(r'[<>:"/\\|?*]', "_", desc)

        filename = f"{safe_author}_{aweme_id}_{safe_desc}.mp4"
        save_path = str(Path(save_dir) / filename)

        success = await self.download_video(download_url, save_path)
        return save_path if success else ""

    async def find_video_in_posts(self, sec_user_id: str, aweme_id: str, max_pages: int = 20) -> Optional[dict]:
        """
        ä»ç”¨æˆ·ä½œå“åˆ—è¡¨ä¸­æŸ¥æ‰¾æŒ‡å®šè§†é¢‘

        Args:
            sec_user_id: ç”¨æˆ·ID
            aweme_id: ä½œå“ID
            max_pages: æœ€å¤šæŸ¥æ‰¾é¡µæ•°

        Returns:
            dict: ä½œå“ä¿¡æ¯,æœªæ‰¾åˆ°è¿”å›None
        """
        logger.info(f"\nğŸ” æ­£åœ¨æœç´¢ä½œå“...")

        max_cursor = 0

        for page in range(max_pages):
            res = await self.fetch_user_posts(sec_user_id, max_cursor, 20)

            if res.get("status_code") != 0:
                logger.error(f"   è·å–å¤±è´¥: {res.get('status_msg', 'æœªçŸ¥é”™è¯¯')}")
                return None

            aweme_list = res.get("aweme_list", [])

            # åœ¨å½“å‰é¡µæŸ¥æ‰¾ç›®æ ‡ä½œå“
            for aweme in aweme_list:
                if aweme.get("aweme_id") == aweme_id:
                    logger.info(f"âœ… æ‰¾åˆ°ä½œå“! (ç¬¬{page+1}é¡µ)")
                    return aweme

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤š
            if not res.get("has_more", False):
                logger.info(f"   å·²æœç´¢å®Œæ‰€æœ‰ {page+1} é¡µ")
                break

            max_cursor = res.get("max_cursor", 0)

            if (page + 1) % 5 == 0:
                logger.info(f"   å·²æœç´¢ {page+1} é¡µ...")

            await asyncio.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«

        logger.error(f"âŒ æœªæ‰¾åˆ°ä½œå“ (æœç´¢äº†{max_pages}é¡µ)")
        return None

    async def fetch_user_posts(self, sec_user_id: str, max_cursor: int = 0, count: int = 20) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·ä½œå“åˆ—è¡¨"""
        params = {
            "device_platform": "webapp",
            "aid": "6383",
            "channel": "channel_pc_web",
            "sec_user_id": sec_user_id,
            "max_cursor": max_cursor,
            "count": count,
            "pc_client_type": 1,
            "version_code": "290100",
            "version_name": "29.1.0",
            "cookie_enabled": "true",
            "screen_width": 1920,
            "screen_height": 1080,
            "browser_language": "zh-CN",
            "browser_platform": "Win32",
            "browser_name": "Chrome",
            "browser_version": "130.0.0.0",
        }

        url = f"{self.USER_POST_ENDPOINT}?{urlencode(params)}"

        try:
            response = await self.client.get(url)
            response.raise_for_status()
            return response.json()
        except Exception as e:
            logger.error(f"è¯·æ±‚å¤±è´¥: {e}")
            return {"status_code": -1}

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯ã€‚"""
        await self.client.aclose()
